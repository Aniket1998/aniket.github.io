[{"authors":["admin"],"categories":null,"content":"I\u0026rsquo;m a Pre-final Year Undergraduate at Indian Institute of Technology, Kanpur majoring in Electrical Engineering and Computer Science and Engineering, broadly interested in the areas of Probabilistic Machine Learning and Approximate Inference, which I\u0026rsquo;m exploring as an Undergraduate Researcher under the mentorship of Prof. Piyush Rai.\nMy sophomore year research work centered around Representation Learning (with focus on Disentangled Representations) and Deep Generative Models for high dimensional sequential data. Under the supervision of Prof. Piyush Rai and Prof. Vinay Namboodiri, I worked on developing hierarchical probabilistic models for joint video and image generation and disentangled representation learning for videos.\nLately, I\u0026rsquo;ve been fascinated by the many applications of Stein\u0026rsquo;s Method in Machine Learning, ranging from Stein Variational Gradient Descent and Stein Point MCMC to Spectral Stein Gradient Estimation for Implicit Models. I\u0026rsquo;m currently working on this subject under Prof. Piyush Rai\u0026rsquo;s guidance, trying to investigate application domains such as Amortized MCMC, Nonparametric KL Minimization, and optimization in Natural Parameter Space, where employing Stein\u0026rsquo;s method may lead to improvements. I\u0026rsquo;m also very interested in the underlying theory of Gradient-Based MCMC Algorithms that function by simulating continuous deterministic or stochastic dynamics, such as (SG)HMC and (SG)LD, and their Riemmanian variants.\nI\u0026rsquo;ve had some exposure to Optimization, though I\u0026rsquo;m much less acquainted with the subject than I\u0026rsquo;d like to be. To this end, I\u0026rsquo;m trying to explore the area of Nonparametric Stochastic Optimization and Online Kernel Learning under the supervision of Prof. Ketan Rajawat. I hope to explore Optimization and Learning Theory rigorously in the future.\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://aniket1998.github.io/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"I\u0026rsquo;m a Pre-final Year Undergraduate at Indian Institute of Technology, Kanpur majoring in Electrical Engineering and Computer Science and Engineering, broadly interested in the areas of Probabilistic Machine Learning and Approximate Inference, which I\u0026rsquo;m exploring as an Undergraduate Researcher under the mentorship of Prof. Piyush Rai.\nMy sophomore year research work centered around Representation Learning (with focus on Disentangled Representations) and Deep Generative Models for high dimensional sequential data. Under the supervision of Prof.","tags":null,"title":"Aniket Das","type":"authors"},{"authors":["Yatin Dandi","Aniket Das","Soumye Singhal","Piyush Rai","Vinay P. Namboodiri"],"categories":[],"content":"We propose a hierarchical model that first generates a summary frame for the video, and then models individual frames by adding to the summary frame\u0026rsquo;s latent code, sequentially dependent residual vectors conditioned on the summary frame. We further extended this idea to video generation models that disentangle content from dynamics, by adding to the base content representation, a residual vector at each timestep conditioned on the base content vector and the dynamics of the given timestep. Currently submitted to Winter Conference on the Applications of Computer Vision (WACV) 2020. Pre-print and code will be made public soon\n","date":1568165640,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1568165640,"objectID":"549e2c4434ae76f05c34b68111b994d1","permalink":"https://aniket1998.github.io/publication/2wacv/","publishdate":"2019-09-11T07:04:00+05:30","relpermalink":"/publication/2wacv/","section":"publication","summary":"We propose a hierarchical model that first generates a summary frame for the video, and then models individual frames by adding to the summary frame\u0026rsquo;s latent code, sequentially dependent residual vectors conditioned on the summary frame. We further extended this idea to video generation models that disentangle content from dynamics, by adding to the base content representation, a residual vector at each timestep conditioned on the base content vector and the dynamics of the given timestep.","tags":[],"title":"Joint Image and Video Generation using Residual Vectors","type":"publication"},{"authors":["Aniket Das","Avik Pal"],"categories":[],"content":"TorchGAN is a PyTorch based framework for writing succinct and comprehensible code for training and evaluation of Generative Adversarial Networks. The framework\u0026rsquo;s modular design allows effortless customization of the model architecture, loss functions, training paradigms, and evaluation metrics and its features bear almost zero overhead over vanilla PyTorch. Currently submitted to Journal of Machine Learning Research: Machine Learning Open Source Software (JMLR MLOSS). An arXiv preprint is available here\n","date":1567907634,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1567907634,"objectID":"98cf9df18a737aba9ea383cf884eee23","permalink":"https://aniket1998.github.io/publication/1torchgan/","publishdate":"2019-09-11T07:23:54+05:30","relpermalink":"/publication/1torchgan/","section":"publication","summary":"TorchGAN is a PyTorch based framework for writing succinct and comprehensible code for training and evaluation of Generative Adversarial Networks. The framework\u0026rsquo;s modular design allows effortless customization of the model architecture, loss functions, training paradigms, and evaluation metrics and its features bear almost zero overhead over vanilla PyTorch. Currently submitted to Journal of Machine Learning Research: Machine Learning Open Source Software (JMLR MLOSS). An arXiv preprint is available here","tags":[],"title":"TorchGAN: A Flexible Framework for GAN Training and Evaluation","type":"publication"}]